## MANDATORY url to elasticsearch
# es:

## Name of the dataset
dataset: default

osm: # A file or a url MUST be defined
  file: # Ignored if a url is defined
  url: # Url to a .osm.pbf file that will be downloaded

# admin:
#   ## If present will use the admins from cosmogony
#   cosmogony:
#     ## This can be use with 2 use cases:
#     ## use 'file' to give the path to an already generated cosmogony file
#     file:
#     ## or use the variables below to generate a cosmogony file on the fly
#     ## output directory where to write the cosmogony.jsonl.gz
#     output_dir:
#     ## optional parameter (only if run without docker) cosmogony source directory (to find libpostal)
#     directory:
#     nb_shards:  # control the number of shards of the ES index
#     nb_replicas:  # control the number of replicas of the ES index
#     langs: # languages to import i18n names and labels (codes separated by ,)
#     disable_voronoi:  # set to truthy value to disable voronoi geometries generation
#   ## If present will use the admins from osm
#   osm:
#     levels:
#       - 8
#     nb_shards:  # control the number of shards of the ES index
#     nb_replicas:  # control the number of replicas of the ES index



# # If present, this will control the import of the Point Of Interest
# poi:
#   ## If present will use fafnir to import the poi
#   fafnir:
#     ## connection string to postgresql (format: postgres://{user}:{pwd}@{host}:{post})
#     pg:
#     ## number of threads to use
#     nb_threads:
#     ## bounding box
#     bounding-box:
#     nb_shards:  # control the number of shards of the ES index
#     nb_replicas:  # control the number of replicas of the ES index
#     langs: # languages to import i18n names and labels (codes separated by ,)
#   ## If present will use osm2mimir to import the poi
#   osm:
#     poi_config: # optional path to json file with POI-config and filters
#     nb_shards:  # control the number of shards of the ES index
#     nb_replicas:  # control the number of replicas of the ES index

addresses:
  # Use the deduplication to merge addresses from different sources.
  use_deduplicator: false

  # If set to true, the deduplication step will be performed only to build the
  # initial base of addresses. If there is already a file generated by
  # deduplication, no computation will be performed.
  skip_deduplication: true

  oa:
    path: # Path to .csv, or a directory with multiple .csv (ignored if 'url' is defined)
    url: # Url where to download OpenAddresses data
    include: # List of file patterns to include from path
      - lu/**.csv
      # - fr/**.csv
    nb_threads: # number of threads to use
#   nb_shards:  # control the number of shards of the ES index
#   nb_replicas:  # control the number of replicas of the ES index

  bano:
    file: # Path to the bano file, ignored if url is defined
    url: # https://bano.openstreetmap.fr/data/full.csv.gz
    nb_threads: # number of threads to use
#   nb_shards:  # control the number of shards of the ES index
#   nb_replicas:  # control the number of replicas of the ES index

  # Specify an OSM file to import addresses from.
  # NOTE: this section will be ignored if `use_deduplicator` is set to false.
  osm:
    file: # Path to the .pbf file (ignored if 'url' is defined)
    url: # https://download.geofabrik.de/europe/luxembourg-latest.osm.pbf

# street:
#   nb_shards:  # control the number of shards of the ES index
#   nb_replicas:  # control the number of replicas of the ES index
#   osm_db_file:  # temporary file to write osm db and reduce memory usage  (optional)

## name of the geocoder region to run. default is france
# geocoder_tester_region: luxembourg
